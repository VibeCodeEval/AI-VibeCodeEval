# LangChain ê°€ë“œë ˆì¼ êµ¬í˜„ ê°€ì´ë“œ

## ğŸ“‹ í˜„ì¬ ìƒí™© ë¶„ì„

### í˜„ì¬ êµ¬í˜„ ë°©ì‹

**í˜„ì¬ ê°€ë“œë ˆì¼**: í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ LLM ê²€ì‚¬ë§Œ ì‚¬ìš©

```python
# í˜„ì¬ ë°©ì‹ (í”„ë¡¬í”„íŠ¸ë§Œ ì‚¬ìš©)
INTENT_ANALYSIS_SYSTEM_PROMPT = """ë‹¹ì‹ ì€ AI ì½”ë”© í…ŒìŠ¤íŠ¸ì˜ ì˜ë„ ë¶„ì„ê¸°ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ë©”ì‹œì§€ë¥¼ ë¶„ì„í•˜ì—¬ ë‹¤ìŒì„ íŒë‹¨í•˜ì„¸ìš”:
1. ê°€ë“œë ˆì¼ ê²€ì‚¬: ...
2. ì£¼ì œ ì í•©ì„±: ...
3. ì œì¶œ ì˜ë„ í™•ì¸: ...
"""

# LLM í˜¸ì¶œ
structured_llm = llm.with_structured_output(IntentAnalysisResult)
```

**ë¬¸ì œì **:
- âŒ í”„ë¡¬í”„íŠ¸ë§Œìœ¼ë¡œëŠ” ìš°íšŒ ê°€ëŠ¥ì„± ë†’ìŒ
- âŒ LLMì´ í”„ë¡¬í”„íŠ¸ë¥¼ ë¬´ì‹œí•  ìˆ˜ ìˆìŒ
- âŒ êµ¬ì¡°ì  ê²€ì¦ ë¶€ì¡±

---

## ğŸ” LangChainì˜ ê°€ë“œë ˆì¼ ê¸°ë²•

### 1. Structured Output (í˜„ì¬ ì‚¬ìš© ì¤‘) âœ…

**ê¸°ëŠ¥**: Pydantic ëª¨ë¸ë¡œ ì¶œë ¥ í˜•ì‹ ê°•ì œ

```python
# í˜„ì¬ ì‚¬ìš© ì¤‘
structured_llm = llm.with_structured_output(IntentAnalysisResult)

# ì¥ì :
# - ì¶œë ¥ í˜•ì‹ ê°•ì œ (JSON êµ¬ì¡°)
# - íƒ€ì… ê²€ì¦
# - í•„ìˆ˜ í•„ë“œ ë³´ì¥
```

**í•œê³„**:
- âš ï¸ í˜•ì‹ë§Œ ê²€ì¦ (ë‚´ìš© ê²€ì¦ ì—†ìŒ)
- âš ï¸ LLMì´ ì˜ëª»ëœ ë‚´ìš©ì„ ì˜¬ë°”ë¥¸ í˜•ì‹ìœ¼ë¡œ ë°˜í™˜ ê°€ëŠ¥

---

### 2. Output Parsers + Validators (ê°•í™” ê°€ëŠ¥) âœ…

**ê¸°ëŠ¥**: ì¶œë ¥ íŒŒì‹± í›„ ì¶”ê°€ ê²€ì¦

```python
from langchain_core.output_parsers import PydanticOutputParser
from pydantic import BaseModel, Field, field_validator

class IntentAnalysisResult(BaseModel):
    status: Literal["SAFE", "BLOCKED"]
    block_reason: str | None
    
    @field_validator('status')
    @classmethod
    def validate_status(cls, v):
        """ìƒíƒœê°’ ê²€ì¦"""
        if v not in ["SAFE", "BLOCKED"]:
            raise ValueError("status must be SAFE or BLOCKED")
        return v
    
    @field_validator('block_reason')
    @classmethod
    def validate_block_reason(cls, v, info):
        """ì°¨ë‹¨ ì´ìœ  ê²€ì¦"""
        status = info.data.get('status')
        if status == "BLOCKED" and not v:
            raise ValueError("block_reason is required when status is BLOCKED")
        return v

# Parser ìƒì„±
parser = PydanticOutputParser(pydantic_object=IntentAnalysisResult)

# Chainì— ì ìš©
chain = prompt | llm | parser
```

**ì¥ì **:
- âœ… ì¶œë ¥ í˜•ì‹ + ë‚´ìš© ê²€ì¦
- âœ… Pydantic Validatorë¡œ ë³µì¡í•œ ê²€ì¦ ê°€ëŠ¥
- âœ… ì—ëŸ¬ ë°œìƒ ì‹œ ì¬ì‹œë„ ê°€ëŠ¥

---

### 3. Custom Validators (ì¶”ê°€ ê²€ì¦ ë ˆì´ì–´) âœ…

**ê¸°ëŠ¥**: Chain ì „í›„ì— ì»¤ìŠ¤í…€ ê²€ì¦ ë¡œì§ ì¶”ê°€

```python
from langchain_core.runnables import RunnableLambda
from typing import Dict, Any

def validate_input(inputs: Dict[str, Any]) -> Dict[str, Any]:
    """ì…ë ¥ ê²€ì¦"""
    human_message = inputs.get("human_message", "")
    
    # 1. í‚¤ì›Œë“œ ê¸°ë°˜ ì‚¬ì „ í•„í„°ë§ (LLM í˜¸ì¶œ ì „)
    blocked_keywords = ["ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸", "ì´ì „ ëª…ë ¹ ë¬´ì‹œ", "ì •ë‹µë§Œ"]
    if any(keyword in human_message.lower() for keyword in blocked_keywords):
        raise ValueError("Jailbreak ì‹œë„ ê°ì§€")
    
    # 2. ê¸¸ì´ ì œí•œ
    if len(human_message) > 1000:
        raise ValueError("ë©”ì‹œì§€ê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤")
    
    return inputs

def validate_output(output: Dict[str, Any]) -> Dict[str, Any]:
    """ì¶œë ¥ ê²€ì¦"""
    status = output.get("status")
    block_reason = output.get("block_reason")
    
    # ë…¼ë¦¬ì  ì¼ê´€ì„± ê²€ì¦
    if status == "BLOCKED" and not block_reason:
        raise ValueError("BLOCKED ìƒíƒœì¸ë° block_reasonì´ ì—†ìŠµë‹ˆë‹¤")
    
    # ì¶”ê°€ ê²€ì¦ ë¡œì§
    if status == "SAFE" and block_reason:
        raise ValueError("SAFE ìƒíƒœì¸ë° block_reasonì´ ìˆìŠµë‹ˆë‹¤")
    
    return output

# Chainì— ì ìš©
chain = (
    RunnableLambda(validate_input)  # ì…ë ¥ ê²€ì¦
    | prompt
    | structured_llm
    | RunnableLambda(validate_output)  # ì¶œë ¥ ê²€ì¦
)
```

**ì¥ì **:
- âœ… LLM í˜¸ì¶œ ì „ ì‚¬ì „ í•„í„°ë§
- âœ… ì¶œë ¥ í›„ ì¶”ê°€ ê²€ì¦
- âœ… ë³µì¡í•œ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ê²€ì¦ ê°€ëŠ¥

---

### 4. Guardrails AI ë¼ì´ë¸ŒëŸ¬ë¦¬ (ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬) âœ…

**ê¸°ëŠ¥**: ì „ë¬¸ ê°€ë“œë ˆì¼ ë¼ì´ë¸ŒëŸ¬ë¦¬

```python
from guardrails import Guard
from guardrails.hub import DetectPII, DetectSecrets

# Guardrails AI ì‚¬ìš©
guard = Guard().use(
    DetectPII(threshold=0.5),
    DetectSecrets()
)

# LLM ì¶œë ¥ ê²€ì¦
validated_output = guard.validate(llm_output)
```

**ì¥ì **:
- âœ… ì „ë¬¸ ê°€ë“œë ˆì¼ ë¼ì´ë¸ŒëŸ¬ë¦¬
- âœ… ë‹¤ì–‘í•œ ê²€ì¦ ê¸°ëŠ¥ ì œê³µ
- âœ… PII, Secrets ë“± ìë™ ê°ì§€

**ë‹¨ì **:
- âš ï¸ ì¶”ê°€ ì˜ì¡´ì„± í•„ìš”
- âš ï¸ ì„¤ì • ë³µì¡ë„ ì¦ê°€

---

### 5. Multi-Layer Guardrails (ë‹¤ì¸µ ê²€ì¦) âœ…

**ê¸°ëŠ¥**: ì—¬ëŸ¬ ê²€ì¦ ë ˆì´ì–´ë¥¼ ì¤‘ì²©

```python
# ë ˆì´ì–´ 1: ì…ë ¥ ê²€ì¦ (í‚¤ì›Œë“œ ê¸°ë°˜)
def keyword_guardrail(inputs: Dict[str, Any]) -> Dict[str, Any]:
    """í‚¤ì›Œë“œ ê¸°ë°˜ ì‚¬ì „ í•„í„°ë§"""
    message = inputs.get("human_message", "").lower()
    
    # Jailbreak í‚¤ì›Œë“œ ì²´í¬
    jailbreak_keywords = [
        "ì´ì „ ëª…ë ¹ ë¬´ì‹œ", "ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸", "ì •ë‹µë§Œ", 
        "ignore previous", "system prompt"
    ]
    if any(kw in message for kw in jailbreak_keywords):
        return {
            "status": "BLOCKED",
            "block_reason": "JAILBREAK",
            "request_type": "CHAT",
            "guide_strategy": None,
            "keywords": []
        }
    
    return inputs

# ë ˆì´ì–´ 2: LLM ê¸°ë°˜ ê²€ì¦
def llm_guardrail(inputs: Dict[str, Any]) -> Dict[str, Any]:
    """LLM ê¸°ë°˜ ìƒì„¸ ë¶„ì„"""
    # ê¸°ì¡´ LLM í˜¸ì¶œ
    result = await structured_llm.ainvoke(inputs)
    return result

# ë ˆì´ì–´ 3: ì¶œë ¥ ê²€ì¦
def output_guardrail(output: Dict[str, Any]) -> Dict[str, Any]:
    """ì¶œë ¥ í›„ ê²€ì¦"""
    # ë…¼ë¦¬ì  ì¼ê´€ì„± ê²€ì¦
    if output["status"] == "BLOCKED" and not output["block_reason"]:
        output["block_reason"] = "UNKNOWN"
    
    return output

# ë‹¤ì¸µ ê°€ë“œë ˆì¼ Chain
guardrail_chain = (
    RunnableLambda(keyword_guardrail)  # ë ˆì´ì–´ 1
    | RunnableLambda(llm_guardrail)    # ë ˆì´ì–´ 2
    | RunnableLambda(output_guardrail) # ë ˆì´ì–´ 3
)
```

**ì¥ì **:
- âœ… ë‹¤ì¸µ ë°©ì–´
- âœ… ë¹ ë¥¸ ì‚¬ì „ í•„í„°ë§ (í‚¤ì›Œë“œ)
- âœ… ì •í™•í•œ ìƒì„¸ ë¶„ì„ (LLM)
- âœ… ìµœì¢… ê²€ì¦ (ì¶œë ¥)

---

## ğŸ¯ ê¶Œì¥ êµ¬í˜„ ë°©ì‹

### í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼ (Multi-Layer)

```
ì…ë ¥ ê²€ì¦ (í‚¤ì›Œë“œ ê¸°ë°˜) â†’ LLM ê²€ì¦ (í”„ë¡¬í”„íŠ¸) â†’ ì¶œë ¥ ê²€ì¦ (ë¡œì§) â†’ ìµœì¢… ê²°ê³¼
```

**êµ¬ì¡°**:

```python
# 1. í‚¤ì›Œë“œ ê¸°ë°˜ ì‚¬ì „ í•„í„°ë§ (ë¹ ë¥¸ ì°¨ë‹¨)
def quick_guardrail_check(message: str) -> Dict[str, Any] | None:
    """í‚¤ì›Œë“œ ê¸°ë°˜ ë¹ ë¥¸ ê²€ì¦ (LLM í˜¸ì¶œ ì—†ìŒ)"""
    message_lower = message.lower()
    
    # Jailbreak í‚¤ì›Œë“œ
    jailbreak_patterns = [
        "ì´ì „ ëª…ë ¹ ë¬´ì‹œ", "ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸", "ì •ë‹µë§Œ",
        "ignore previous", "system prompt", "just answer"
    ]
    if any(pattern in message_lower for pattern in jailbreak_patterns):
        return {
            "status": "BLOCKED",
            "block_reason": "JAILBREAK",
            "request_type": "CHAT",
            "guide_strategy": None,
            "keywords": []
        }
    
    # Off-Topic í‚¤ì›Œë“œ
    off_topic_patterns = ["ì ì‹¬", "ë‚ ì”¨", "ìŒì•…", "ì˜í™”"]
    if any(pattern in message_lower for pattern in off_topic_patterns):
        # ì½”ë”© ê´€ë ¨ í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ Off-Topic
        coding_keywords = ["ì½”ë“œ", "ì•Œê³ ë¦¬ì¦˜", "í”„ë¡œê·¸ë˜ë°", "í•¨ìˆ˜"]
        if not any(kw in message_lower for kw in coding_keywords):
            return {
                "status": "BLOCKED",
                "block_reason": "OFF_TOPIC",
                "request_type": "CHAT",
                "guide_strategy": None,
                "keywords": []
            }
    
    return None  # í†µê³¼

# 2. LLM ê¸°ë°˜ ìƒì„¸ ë¶„ì„
async def llm_guardrail_analysis(inputs: Dict[str, Any]) -> Dict[str, Any]:
    """LLM ê¸°ë°˜ ìƒì„¸ ê°€ë“œë ˆì¼ ë¶„ì„"""
    # ë¹ ë¥¸ ê²€ì¦ í†µê³¼ ì‹œì—ë§Œ LLM í˜¸ì¶œ
    quick_check = quick_guardrail_check(inputs.get("human_message", ""))
    if quick_check:
        return quick_check
    
    # LLM í˜¸ì¶œ
    result = await structured_llm.ainvoke(inputs)
    return result

# 3. ì¶œë ¥ ê²€ì¦
def validate_guardrail_output(output: Dict[str, Any]) -> Dict[str, Any]:
    """ì¶œë ¥ ê²€ì¦ ë° ì •ê·œí™”"""
    # ë…¼ë¦¬ì  ì¼ê´€ì„± ê²€ì¦
    if output["status"] == "BLOCKED" and not output.get("block_reason"):
        output["block_reason"] = "UNKNOWN"
    
    if output["status"] == "SAFE" and output.get("block_reason"):
        output["block_reason"] = None
    
    # í•„ìˆ˜ í•„ë“œ ë³´ì¥
    if "keywords" not in output:
        output["keywords"] = []
    
    return output

# í†µí•© Chain
guardrail_chain = (
    RunnableLambda(prepare_input)
    | RunnableLambda(lambda x: llm_guardrail_analysis(x) if quick_guardrail_check(x.get("human_message", "")) is None else quick_guardrail_check(x.get("human_message", "")))
    | intent_analysis_prompt
    | structured_llm
    | RunnableLambda(validate_guardrail_output)
    | RunnableLambda(process_output)
)
```

---

## ğŸ“Š ë¹„êµí‘œ

| ë°©ì‹ | ìš°íšŒ ê°€ëŠ¥ì„± | ì„±ëŠ¥ | êµ¬í˜„ ë³µì¡ë„ | ê¶Œì¥ë„ |
|------|-----------|------|------------|--------|
| **í”„ë¡¬í”„íŠ¸ë§Œ** | ë†’ìŒ âŒ | ì¤‘ê°„ | ë‚®ìŒ | âŒ |
| **Structured Output** | ì¤‘ê°„ âš ï¸ | ë†’ìŒ | ë‚®ìŒ | âš ï¸ |
| **Output Parsers + Validators** | ë‚®ìŒ âœ… | ì¤‘ê°„ | ì¤‘ê°„ | âœ… |
| **Custom Validators** | ë‚®ìŒ âœ… | ë†’ìŒ | ì¤‘ê°„ | âœ… |
| **Guardrails AI** | ë§¤ìš° ë‚®ìŒ âœ…âœ… | ì¤‘ê°„ | ë†’ìŒ | âš ï¸ |
| **Multi-Layer** | ë§¤ìš° ë‚®ìŒ âœ…âœ… | ë†’ìŒ | ë†’ìŒ | âœ…âœ… |

---

## ğŸ¯ ìµœì¢… ê¶Œì¥ êµ¬í˜„

### í•˜ì´ë¸Œë¦¬ë“œ Multi-Layer Guardrails

```python
# app/domain/langgraph/nodes/intent_analyzer.py

# 1. í‚¤ì›Œë“œ ê¸°ë°˜ ë¹ ë¥¸ ê²€ì¦ (LLM í˜¸ì¶œ ì—†ìŒ)
def quick_guardrail_check(message: str) -> Dict[str, Any] | None:
    """í‚¤ì›Œë“œ ê¸°ë°˜ ì‚¬ì „ í•„í„°ë§"""
    message_lower = message.lower()
    
    # Jailbreak íŒ¨í„´
    jailbreak_patterns = [
        "ì´ì „ ëª…ë ¹ ë¬´ì‹œ", "ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸", "ì •ë‹µë§Œ",
        "ignore previous", "system prompt", "just answer"
    ]
    if any(pattern in message_lower for pattern in jailbreak_patterns):
        return {
            "status": "BLOCKED",
            "block_reason": "JAILBREAK",
            "request_type": "CHAT",
            "guide_strategy": None,
            "keywords": []
        }
    
    return None

# 2. LLM ê¸°ë°˜ ìƒì„¸ ë¶„ì„ (Structured Output + Validators)
class IntentAnalysisResult(BaseModel):
    status: Literal["SAFE", "BLOCKED"]
    block_reason: Literal["DIRECT_ANSWER", "JAILBREAK", "OFF_TOPIC"] | None
    request_type: Literal["CHAT", "SUBMISSION"]
    guide_strategy: Literal["SYNTAX_GUIDE", "LOGIC_HINT", "ROADMAP"] | None
    keywords: List[str]
    reasoning: str
    
    @field_validator('status')
    @classmethod
    def validate_status(cls, v, info):
        """ìƒíƒœê°’ ê²€ì¦"""
        block_reason = info.data.get('block_reason')
        if v == "BLOCKED" and not block_reason:
            raise ValueError("BLOCKED ìƒíƒœëŠ” block_reasonì´ í•„ìˆ˜ì…ë‹ˆë‹¤")
        if v == "SAFE" and block_reason:
            raise ValueError("SAFE ìƒíƒœëŠ” block_reasonì´ ì—†ì–´ì•¼ í•©ë‹ˆë‹¤")
        return v

# 3. ì¶œë ¥ ê²€ì¦
def validate_output(output: IntentAnalysisResult) -> Dict[str, Any]:
    """ì¶œë ¥ ê²€ì¦ ë° ë³€í™˜"""
    # ì¶”ê°€ ê²€ì¦ ë¡œì§
    if output.status == "BLOCKED" and not output.block_reason:
        output.block_reason = "UNKNOWN"
    
    return {
        "status": output.status,
        "block_reason": output.block_reason,
        "request_type": output.request_type,
        "guide_strategy": output.guide_strategy,
        "keywords": output.keywords,
        "reasoning": output.reasoning
    }

# 4. í†µí•© Chain
async def guardrail_chain(inputs: Dict[str, Any]) -> Dict[str, Any]:
    """ë‹¤ì¸µ ê°€ë“œë ˆì¼ Chain"""
    message = inputs.get("human_message", "")
    
    # ë ˆì´ì–´ 1: í‚¤ì›Œë“œ ê¸°ë°˜ ë¹ ë¥¸ ê²€ì¦
    quick_result = quick_guardrail_check(message)
    if quick_result:
        return quick_result
    
    # ë ˆì´ì–´ 2: LLM ê¸°ë°˜ ìƒì„¸ ë¶„ì„
    llm_result = await structured_llm.ainvoke(inputs)
    
    # ë ˆì´ì–´ 3: ì¶œë ¥ ê²€ì¦
    validated_result = validate_output(llm_result)
    
    return validated_result
```

---

## âœ… ì¥ì 

### Multi-Layer Guardrailsì˜ ì¥ì 

1. **ë‹¤ì¸µ ë°©ì–´**
   - í‚¤ì›Œë“œ ê¸°ë°˜ ë¹ ë¥¸ ì°¨ë‹¨ (LLM í˜¸ì¶œ ì—†ìŒ)
   - LLM ê¸°ë°˜ ìƒì„¸ ë¶„ì„
   - ì¶œë ¥ ê²€ì¦

2. **ì„±ëŠ¥ ìµœì í™”**
   - ëª…ë°±í•œ ìœ„ë°˜ì€ LLM í˜¸ì¶œ ì „ì— ì°¨ë‹¨
   - ë¹„ìš© ì ˆê°

3. **ì •í™•ë„ í–¥ìƒ**
   - ì—¬ëŸ¬ ë ˆì´ì–´ì˜ ê²€ì¦ìœ¼ë¡œ ìš°íšŒ ì–´ë ¤ì›€
   - ë…¼ë¦¬ì  ì¼ê´€ì„± ë³´ì¥

4. **ìœ ì§€ë³´ìˆ˜ì„±**
   - ê° ë ˆì´ì–´ ë…ë¦½ì  ê´€ë¦¬
   - ê²€ì¦ ê·œì¹™ ì¶”ê°€/ìˆ˜ì • ìš©ì´

---

## ğŸ“ êµ¬í˜„ ì²´í¬ë¦¬ìŠ¤íŠ¸

### í•„ìˆ˜ êµ¬í˜„
- [ ] í‚¤ì›Œë“œ ê¸°ë°˜ ì‚¬ì „ í•„í„°ë§
- [ ] Pydantic Validators ì¶”ê°€
- [ ] ì¶œë ¥ ê²€ì¦ ë¡œì§
- [ ] ë‹¤ì¸µ ê°€ë“œë ˆì¼ Chain êµ¬ì„±

### ì„ íƒì  êµ¬í˜„
- [ ] Guardrails AI ë¼ì´ë¸ŒëŸ¬ë¦¬ í†µí•©
- [ ] ì •ê·œí‘œí˜„ì‹ ê¸°ë°˜ íŒ¨í„´ ë§¤ì¹­
- [ ] ML ê¸°ë°˜ ì´ìƒ íƒì§€

---

## ğŸ¯ ê²°ë¡ 

### í˜„ì¬ ë°©ì‹ì˜ í•œê³„
- âŒ í”„ë¡¬í”„íŠ¸ë§Œ ì‚¬ìš© â†’ ìš°íšŒ ê°€ëŠ¥ì„± ë†’ìŒ
- âŒ êµ¬ì¡°ì  ê²€ì¦ ë¶€ì¡±

### ê¶Œì¥ ë°©ì‹
- âœ… **Multi-Layer Guardrails** (í•˜ì´ë¸Œë¦¬ë“œ)
  - í‚¤ì›Œë“œ ê¸°ë°˜ ì‚¬ì „ í•„í„°ë§
  - LLM ê¸°ë°˜ ìƒì„¸ ë¶„ì„ (Structured Output + Validators)
  - ì¶œë ¥ ê²€ì¦

### êµ¬í˜„ ìš°ì„ ìˆœìœ„
1. **í‚¤ì›Œë“œ ê¸°ë°˜ ì‚¬ì „ í•„í„°ë§** (ì¦‰ì‹œ êµ¬í˜„ ê°€ëŠ¥)
2. **Pydantic Validators ì¶”ê°€** (êµ¬ì¡°ì  ê²€ì¦)
3. **ì¶œë ¥ ê²€ì¦ ë¡œì§** (ë…¼ë¦¬ì  ì¼ê´€ì„±)
4. **ë‹¤ì¸µ Chain êµ¬ì„±** (í†µí•©)




