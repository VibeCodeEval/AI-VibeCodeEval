#!/usr/bin/env python
"""
Phase 5-C: Chaining íŒŒì¸íŠœë‹ ë°ì´í„° ì¶”ì¶œ ìŠ¤í¬ë¦½íŠ¸

HOLISTIC_FLOW í‰ê°€ ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ì—¬ 6a ë…¸ë“œ(Holistic Flow Evaluator)ì˜ 
Chaining ì „ëµ í‰ê°€ í’ˆì§ˆ ê°œì„ ì— í™œìš©í•©ë‹ˆë‹¤.

ì¶œë ¥ íŒŒì¼:
- chaining_data.jsonl              : ì „ì²´ Chaining í‰ê°€ ë°ì´í„°
- chaining_high_score.jsonl        : ê³ ì  Chaining ì „ëµ (70+)
- chaining_medium_score.jsonl      : ì¤‘ì  Chaining ì „ëµ (40-69)
- chaining_low_score.jsonl         : ì €ì  Chaining ì „ëµ (0-39)
- chaining_examples.json           : Few-shot ì˜ˆì‹œ

ì‚¬ìš©ë²•:
    python scripts/extract_chaining_finetuning_data.py
    python scripts/extract_chaining_finetuning_data.py --output-dir ./custom_output
"""

import argparse
import json
import os
import sys
from collections import defaultdict
from pathlib import Path
from typing import Any

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

import psycopg2
from psycopg2.extras import RealDictCursor
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv(project_root / ".env")


def get_db_config() -> dict:
    """í™˜ê²½ ë³€ìˆ˜ì—ì„œ DB ì„¤ì • ì½ê¸°"""
    return {
        "host": os.getenv("POSTGRES_HOST", "localhost"),
        "port": int(os.getenv("POSTGRES_PORT", 5435)),
        "user": os.getenv("POSTGRES_USER", "postgres"),
        "password": os.getenv("POSTGRES_PASSWORD", "postgres"),
        "database": os.getenv("POSTGRES_DB", "ai_vibe_coding_test"),
    }


def connect_db():
    """PostgreSQL ì—°ê²°"""
    config = get_db_config()
    print(f"[INFO] DB ì—°ê²° ì¤‘: {config['host']}:{config['port']}/{config['database']}")
    conn = psycopg2.connect(
        host=config["host"],
        port=config["port"],
        user=config["user"],
        password=config["password"],
        database=config["database"],
    )
    return conn


# SQL ì¿¼ë¦¬: HOLISTIC_FLOW í‰ê°€ ë°ì´í„° ì¶”ì¶œ
EXTRACT_CHAINING_DATA_SQL = """
SET search_path TO ai_vibe_coding_test;

SELECT 
    pe.id,
    pe.session_id,
    pe.evaluation_type,
    pe.details,
    pe.created_at,
    ps.spec_id AS problem_spec_id
FROM ai_vibe_coding_test.prompt_evaluations pe
LEFT JOIN ai_vibe_coding_test.prompt_sessions ps 
    ON pe.session_id = ps.id
WHERE pe.evaluation_type::text = 'HOLISTIC_FLOW'
    AND pe.turn IS NULL
    AND pe.details->>'score' IS NOT NULL
ORDER BY pe.session_id;
"""


def parse_details(details: dict) -> dict[str, Any]:
    """details JSONB í•„ë“œ íŒŒì‹±"""
    result = {}
    
    # ê¸°ë³¸ í•„ë“œ
    result["score"] = _safe_float(details.get("score"))
    result["analysis"] = details.get("analysis", "")
    
    # í‰ê°€ í•­ëª© íŒŒì‹±
    result["problem_decomposition"] = _parse_evaluation_criterion(
        details.get("problem_decomposition")
    )
    result["feedback_integration"] = _parse_evaluation_criterion(
        details.get("feedback_integration")
    )
    result["strategic_exploration"] = _parse_evaluation_criterion(
        details.get("strategic_exploration")
    )
    
    # structured_logs íŒŒì‹±
    structured_logs = details.get("structured_logs", [])
    result["turn_summaries"] = []
    
    if isinstance(structured_logs, list):
        for log in structured_logs:
            if isinstance(log, dict):
                turn_summary = {
                    "turn": log.get("turn"),
                    "intent": log.get("intent"),
                    "user_summary": log.get("user_prompt_summary") or log.get("user_summary", ""),
                    "ai_summary": log.get("ai_summary", ""),
                    "score": _safe_float(log.get("turn_score") or log.get("score"))
                }
                result["turn_summaries"].append(turn_summary)
    
    return result


def _parse_evaluation_criterion(criterion: Any) -> dict[str, Any]:
    """í‰ê°€ í•­ëª© íŒŒì‹± (score, analysis í¬í•¨)"""
    if isinstance(criterion, dict):
        return {
            "score": _safe_float(criterion.get("score")),
            "analysis": criterion.get("analysis", "")
        }
    elif isinstance(criterion, (int, float)):
        # ì ìˆ˜ë§Œ ìˆëŠ” ê²½ìš°
        return {
            "score": _safe_float(criterion),
            "analysis": ""
        }
    else:
        return {
            "score": None,
            "analysis": ""
        }


def _safe_float(value: Any) -> float | None:
    """ì•ˆì „í•˜ê²Œ float ë³€í™˜"""
    if value is None:
        return None
    try:
        return float(value)
    except (ValueError, TypeError):
        return None


def extract_chaining_data(conn) -> list[dict[str, Any]]:
    """DBì—ì„œ Chaining í‰ê°€ ë°ì´í„° ì¶”ì¶œ"""
    print("[INFO] Chaining í‰ê°€ ë°ì´í„° ì¶”ì¶œ ì¤‘...")
    
    with conn.cursor(cursor_factory=RealDictCursor) as cur:
        cur.execute(EXTRACT_CHAINING_DATA_SQL)
        rows = cur.fetchall()
    
    results = []
    for row in rows:
        details = row.get("details", {})
        if not isinstance(details, dict):
            continue
        
        parsed = parse_details(details)
        
        # ì¶œë ¥ ë ˆì½”ë“œ êµ¬ì„±
        record = {
            "id": f"chaining_session_{row['session_id']}",
            "session_id": row["session_id"],
            "total_score": parsed.get("score"),
            "analysis": parsed.get("analysis", ""),
            "evaluation_criteria": {
                "problem_decomposition": parsed.get("problem_decomposition", {}),
                "feedback_integration": parsed.get("feedback_integration", {}),
                "strategic_exploration": parsed.get("strategic_exploration", {})
            },
            "turn_summaries": parsed.get("turn_summaries", []),
            "turn_count": len(parsed.get("turn_summaries", [])),
            "metadata": {
                "problem_spec_id": row.get("problem_spec_id"),
                "created_at": row["created_at"].isoformat() if row.get("created_at") else None,
            }
        }
        results.append(record)
    
    print(f"[INFO] ì´ {len(results)}ê°œì˜ Chaining í‰ê°€ ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ")
    return results


def clean_data(chaining_data: list[dict]) -> list[dict]:
    """ë°ì´í„° ì •ì œ: scoreê°€ NULLì´ê±°ë‚˜ analysisê°€ ë¹„ì–´ìˆëŠ” ë°ì´í„° ì œì™¸"""
    cleaned = []
    for data in chaining_data:
        score = data.get("total_score")
        analysis = data.get("analysis", "").strip()
        
        # í‰ê°€ í•­ëª©ì´ ìµœì†Œ 1ê°œ ì´ìƒ ìˆëŠ”ì§€ í™•ì¸
        criteria = data.get("evaluation_criteria", {})
        has_criteria = any(
            criterion.get("score") is not None
            for criterion in criteria.values()
        )
        
        if score is not None and analysis and has_criteria:
            cleaned.append(data)
    
    print(f"[INFO] ì •ì œ ê²°ê³¼: {len(cleaned)}ê°œ (ì „ì²´ {len(chaining_data)}ê°œ ì¤‘)")
    return cleaned


def categorize_by_score(chaining_data: list[dict]) -> dict[str, list[dict]]:
    """ì ìˆ˜ëŒ€ë³„ë¡œ ë¶„ë¥˜"""
    by_score = {
        "high": [],      # 70+
        "medium": [],    # 40-69
        "low": [],       # 0-39
    }
    
    for data in chaining_data:
        score = data.get("total_score")
        if score is None:
            continue
        elif score >= 70:
            by_score["high"].append(data)
        elif score >= 40:
            by_score["medium"].append(data)
        else:
            by_score["low"].append(data)
    
    return by_score


def select_few_shot_examples(chaining_data: list[dict]) -> dict:
    """Few-shot ì˜ˆì‹œ ì„ ì • (ì ìˆ˜ëŒ€ë³„/í‰ê°€ í•­ëª©ë³„ ëŒ€í‘œ ì˜ˆì‹œ)"""
    examples = {
        "by_score": {
            "high": [],
            "medium": [],
            "low": []
        },
        "by_criterion": {
            "problem_decomposition": {"high": [], "low": []},
            "feedback_integration": {"high": [], "low": []},
            "strategic_exploration": {"high": [], "low": []}
        },
        "best_examples": []  # ì „ì²´ì ìœ¼ë¡œ ìš°ìˆ˜í•œ ì˜ˆì‹œ
    }
    
    # ì ìˆ˜ëŒ€ë³„ ì˜ˆì‹œ ì„ ì •
    by_score = categorize_by_score(chaining_data)
    for score_level, items in by_score.items():
        # analysisê°€ ëª…í™•í•œ ê²ƒ ìš°ì„ 
        sorted_items = sorted(
            items,
            key=lambda x: (
                len(x.get("analysis", "")),  # analysis ê¸¸ì´
                x.get("total_score", 0)  # ì ìˆ˜
            ),
            reverse=True
        )
        examples["by_score"][score_level] = sorted_items[:5]
    
    # í‰ê°€ í•­ëª©ë³„ ì˜ˆì‹œ ì„ ì •
    for criterion_name in ["problem_decomposition", "feedback_integration", "strategic_exploration"]:
        # ê³ ì  ì˜ˆì‹œ (í•´ë‹¹ í•­ëª© ì ìˆ˜ 70+)
        high_items = [
            data for data in chaining_data
            if data.get("evaluation_criteria", {}).get(criterion_name, {}).get("score", 0) >= 70
        ]
        sorted_high = sorted(
            high_items,
            key=lambda x: (
                len(x.get("evaluation_criteria", {}).get(criterion_name, {}).get("analysis", "")),
                x.get("evaluation_criteria", {}).get(criterion_name, {}).get("score", 0)
            ),
            reverse=True
        )
        examples["by_criterion"][criterion_name]["high"] = sorted_high[:3]
        
        # ì €ì  ì˜ˆì‹œ (í•´ë‹¹ í•­ëª© ì ìˆ˜ < 40)
        low_items = [
            data for data in chaining_data
            if data.get("evaluation_criteria", {}).get(criterion_name, {}).get("score", 0) < 40
        ]
        sorted_low = sorted(
            low_items,
            key=lambda x: (
                len(x.get("evaluation_criteria", {}).get(criterion_name, {}).get("analysis", "")),
                x.get("total_score", 0)
            ),
            reverse=True
        )
        examples["by_criterion"][criterion_name]["low"] = sorted_low[:3]
    
    # ìµœê³  ì˜ˆì‹œ (ì „ì²´ ì ìˆ˜ 70+ ì´ê³  ëª¨ë“  í•­ëª©ì´ ìš°ìˆ˜í•œ ê²ƒ)
    high_score = by_score["high"]
    sorted_best = sorted(
        high_score,
        key=lambda x: (
            sum([
                criterion.get("score", 0)
                for criterion in x.get("evaluation_criteria", {}).values()
                if isinstance(criterion, dict)
            ]),
            len(x.get("analysis", "")),
            x.get("total_score", 0)
        ),
        reverse=True
    )
    examples["best_examples"] = sorted_best[:10]
    
    return examples


def save_jsonl(data: list[dict], filepath: Path):
    """JSONL í˜•ì‹ìœ¼ë¡œ ì €ì¥"""
    filepath.parent.mkdir(parents=True, exist_ok=True)
    with open(filepath, "w", encoding="utf-8") as f:
        for item in data:
            f.write(json.dumps(item, ensure_ascii=False, default=str) + "\n")
    print(f"[INFO] ì €ì¥ ì™„ë£Œ: {filepath} ({len(data)}ê°œ ë ˆì½”ë“œ)")


def save_json(data: dict, filepath: Path):
    """JSON í˜•ì‹ìœ¼ë¡œ ì €ì¥"""
    filepath.parent.mkdir(parents=True, exist_ok=True)
    with open(filepath, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2, default=str)
    print(f"[INFO] ì €ì¥ ì™„ë£Œ: {filepath}")


def print_statistics(chaining_data: list[dict], cleaned: list[dict]):
    """í†µê³„ ì •ë³´ ì¶œë ¥"""
    print("\n" + "=" * 60)
    print("ğŸ“Š ì¶”ì¶œ ê²°ê³¼ í†µê³„")
    print("=" * 60)
    
    print(f"\nğŸ“Œ ì „ì²´ Chaining í‰ê°€ ë°ì´í„°: {len(chaining_data)}ê°œ")
    print(f"   - ì •ì œëœ ë°ì´í„°: {len(cleaned)}ê°œ")
    
    # ì ìˆ˜ëŒ€ë³„ ë¶„í¬
    by_score = categorize_by_score(cleaned)
    print(f"\nğŸ“Œ ì ìˆ˜ëŒ€ë³„ ë¶„í¬:")
    print(f"   - ê³ ì  (70+): {len(by_score['high'])}ê°œ")
    print(f"   - ì¤‘ì  (40-69): {len(by_score['medium'])}ê°œ")
    print(f"   - ì €ì  (0-39): {len(by_score['low'])}ê°œ")
    
    # í‰ê°€ í•­ëª©ë³„ í‰ê·  ì ìˆ˜
    if cleaned:
        problem_decomp_scores = [
            data.get("evaluation_criteria", {}).get("problem_decomposition", {}).get("score")
            for data in cleaned
            if data.get("evaluation_criteria", {}).get("problem_decomposition", {}).get("score") is not None
        ]
        feedback_scores = [
            data.get("evaluation_criteria", {}).get("feedback_integration", {}).get("score")
            for data in cleaned
            if data.get("evaluation_criteria", {}).get("feedback_integration", {}).get("score") is not None
        ]
        strategic_scores = [
            data.get("evaluation_criteria", {}).get("strategic_exploration", {}).get("score")
            for data in cleaned
            if data.get("evaluation_criteria", {}).get("strategic_exploration", {}).get("score") is not None
        ]
        
        print(f"\nğŸ“Œ í‰ê°€ í•­ëª©ë³„ í‰ê·  ì ìˆ˜:")
        if problem_decomp_scores:
            print(f"   - ë¬¸ì œ ë¶„í•´ (Problem Decomposition): {sum(problem_decomp_scores) / len(problem_decomp_scores):.2f}")
        if feedback_scores:
            print(f"   - í”¼ë“œë°± ìˆ˜ìš©ì„± (Feedback Integration): {sum(feedback_scores) / len(feedback_scores):.2f}")
        if strategic_scores:
            print(f"   - ì „ëµì  íƒìƒ‰ (Strategic Exploration): {sum(strategic_scores) / len(strategic_scores):.2f}")
    
    # í„´ ìˆ˜ ë¶„í¬
    turn_counts = [data.get("turn_count", 0) for data in cleaned]
    if turn_counts:
        print(f"\nğŸ“Œ í„´ ìˆ˜ ë¶„í¬:")
        print(f"   - í‰ê· : {sum(turn_counts) / len(turn_counts):.2f}í„´")
        print(f"   - ìµœëŒ€: {max(turn_counts)}í„´")
        print(f"   - ìµœì†Œ: {min(turn_counts)}í„´")
    
    # ì „ì²´ ì ìˆ˜ í†µê³„
    scores = [data.get("total_score") for data in cleaned if data.get("total_score") is not None]
    if scores:
        print(f"\nğŸ“Œ ì „ì²´ ì ìˆ˜ í†µê³„:")
        print(f"   - í‰ê· : {sum(scores) / len(scores):.2f}")
        print(f"   - ìµœê³ : {max(scores):.2f}")
        print(f"   - ìµœì €: {min(scores):.2f}")
    
    print("\n" + "=" * 60)


def main():
    parser = argparse.ArgumentParser(
        description="Phase 5-C: Chaining íŒŒì¸íŠœë‹ ë°ì´í„° ì¶”ì¶œ"
    )
    parser.add_argument(
        "--output-dir",
        type=str,
        default=".maestro/data/finetuning/phase5c_chaining",
        help="ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: .maestro/data/finetuning/phase5c_chaining)"
    )
    args = parser.parse_args()
    
    output_dir = Path(project_root) / args.output_dir
    
    print("=" * 60)
    print("ğŸš€ Phase 5-C: Chaining íŒŒì¸íŠœë‹ ë°ì´í„° ì¶”ì¶œ")
    print(f"   ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir}")
    print("=" * 60)
    
    try:
        # DB ì—°ê²°
        conn = connect_db()
        
        # ë°ì´í„° ì¶”ì¶œ
        chaining_data = extract_chaining_data(conn)
        
        if not chaining_data:
            print("[WARN] ì¶”ì¶œëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. DBì— HOLISTIC_FLOW ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
            return
        
        # ë°ì´í„° ì •ì œ
        cleaned = clean_data(chaining_data)
        
        if not cleaned:
            print("[WARN] ì •ì œëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. score, analysis, í‰ê°€ í•­ëª©ì´ ìˆëŠ” ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            return
        
        # í†µê³„ ì¶œë ¥
        print_statistics(chaining_data, cleaned)
        
        # ë¶„ë¥˜
        by_score = categorize_by_score(cleaned)
        
        # íŒŒì¼ ì €ì¥
        print("\nğŸ“ íŒŒì¼ ì €ì¥ ì¤‘...")
        
        # 1. ì „ì²´ Chaining ë°ì´í„°
        save_jsonl(chaining_data, output_dir / "chaining_data.jsonl")
        
        # 2. ì •ì œëœ ë°ì´í„° (cleanedëŠ” ì´ë¯¸ ì €ì¥ë¨)
        save_jsonl(cleaned, output_dir / "chaining_cleaned.jsonl")
        
        # 3. ì ìˆ˜ëŒ€ë³„ ë¶„ë¥˜
        save_jsonl(by_score["high"], output_dir / "chaining_high_score.jsonl")
        save_jsonl(by_score["medium"], output_dir / "chaining_medium_score.jsonl")
        save_jsonl(by_score["low"], output_dir / "chaining_low_score.jsonl")
        
        # 4. Few-shot ì˜ˆì‹œ
        examples = select_few_shot_examples(cleaned)
        save_json(examples, output_dir / "chaining_examples.json")
        
        print("\nâœ… Phase 5-C ì™„ë£Œ!")
        print(f"   ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir}")
        
        conn.close()
        
    except psycopg2.Error as e:
        print(f"[ERROR] DB ì˜¤ë¥˜: {e}")
        sys.exit(1)
    except Exception as e:
        print(f"[ERROR] ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
